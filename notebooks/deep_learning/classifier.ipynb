{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79def733-c4d5-45d0-bd80-5ff2b5b2325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "# from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "# Keras utilities\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "#from tensorflow.keras.models import Model\n",
    "#from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2736a0a-c993-4684-b5ba-554f79660be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from files import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bded242-7790-47eb-8234-1c3e76f44f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simple example network for visualising the filters and layers.\n",
    "\"\"\"\n",
    "\n",
    "num_classes = 2\n",
    "image_size = 8\n",
    "\n",
    "num_filters = 8 # also 4, 16\n",
    "num_filters_l2 = 16\n",
    "filter_size = 3 # also 4,5\n",
    "# num_hidden = 64 # also 16?)\n",
    "\n",
    "# batch_size = 5 # Half the images sent in each mini-batch\n",
    "#batch_size = 10 # All images in each batch\n",
    "batch_size = 1 # One at a time\n",
    "# batch_size = 2 # 2 at a time\n",
    "\n",
    "# initializer = initializers.Constant(0.1)\n",
    "kernel_init = initializers.RandomUniform(minval=-0.01, maxval=0.01)\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "data_augmentation = Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomFlip(\"vertical\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.5, interpolation='nearest', fill_mode='constant', fill_value=0.0),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        layers.Input((image_size, image_size, 3)),\n",
    "        data_augmentation,\n",
    "        layers.Rescaling(1.0 / 255),                       # Rescale to 0..1\n",
    "        layers.Conv2D(num_filters, filter_size, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init),\n",
    "        layers.MaxPooling2D(), # Halve the resolution to 4x4\n",
    "        layers.Conv2D(num_filters_l2, filter_size, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init),\n",
    "        layers.MaxPooling2D(), # Halve the resolution to 2x2\n",
    "        # layers.Conv2D(num_filters, filter_size, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init),\n",
    "        # layers.MaxPooling2D(),\n",
    "        # layers.Dropout(0.2),\n",
    "        layers.Flatten(),                                                                       # Flatten filters into a 1D vector of vars\n",
    "        ##layers.Dense(num_hidden, activation=\"relu\"),                                            # Hidden layer\n",
    "        layers.Dense(num_classes, activation=\"softmax\", kernel_initializer=kernel_init),                                        # output layer\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary(line_length=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9336bfe9-b1be-437c-a623-1bb6de1ee980",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.report_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a66972-ecdb-4e64-a9bf-37b3735f3aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some training\n",
    "\n",
    "# data_dir = \"images_noisy_RGB_train\"\n",
    "# train_data_dir = \"images_clean/train\"  # Clean training data\n",
    "# train_data_dir = \"images_noisy_GB_train/train\"  # Random FP in training set\n",
    "data_dir = \"files/images_red\"  # Single-channel (red) images\n",
    "\n",
    "train_data_dir = data_dir + \"/train\"\n",
    "valid_data_dir = data_dir + \"/val\"\n",
    "test_data_dir = data_dir + \"/test\"\n",
    "\n",
    "train_generator = tf.keras.utils.image_dataset_from_directory(train_data_dir, image_size=(image_size,image_size), batch_size = batch_size)\n",
    "valid_generator = tf.keras.utils.image_dataset_from_directory(valid_data_dir, image_size=(image_size,image_size), batch_size = batch_size)\n",
    "    \n",
    "# model.fit_generator(train_generator, epochs=fine_tune_epochs, validation_data=valid_generator, callbacks = callbacks)\n",
    "model.fit(train_generator, validation_data=valid_generator, epochs=EPOCHS, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7402c01-cf39-49d5-bf93-696d6ddfb4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "test_images = os.listdir(test_data_dir)\n",
    "class_names = ['X', '0']\n",
    "tot_correct = 0\n",
    "for image_file in test_images:\n",
    "    img = tf.keras.utils.load_img(os.path.join(test_data_dir, image_file), target_size=(image_size, image_size))\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create a batch\n",
    "    predictions = model.predict(img_array)\n",
    "    scores = tf.nn.softmax(predictions[0])\n",
    "    score = np.max(scores)\n",
    "    ans = class_names[np.argmax(scores)]\n",
    "    correct = (ans == image_file[0]) # Filename is prefixed with class\n",
    "    tot_correct += correct\n",
    "    print(f\"{image_file}: {ans} {score} {correct}\")\n",
    "print(\"==================================\")\n",
    "print(f\"{tot_correct} of {len(test_images)} correct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8bb0b9-b61a-4582-b674-112637892f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"========================= TRAINED WEIGHTS ===============================\")\n",
    "utils.report_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971b054d-8681-421f-beba-feec55122043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example \"X\"\n",
    "utils.report_outputs(model, os.path.join(test_data_dir, test_images[8]), image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb846c4-4522-4f88-a448-ffcb0826325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example \"O\"\n",
    "utils.report_outputs(model, os.path.join(test_data_dir, test_images[4]), image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454b28d1-3956-420a-8f34-8d50b0a78532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
